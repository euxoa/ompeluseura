{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Kaisaniemi-Snow-Python.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFhoDVXztWxR",
        "colab_type": "text"
      },
      "source": [
        "# Depth of snow cover in Kaisaniemi Helsinki"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP-hlWb_tWxU",
        "colab_type": "text"
      },
      "source": [
        "This notebook investigates the depth of snow in Kaisaniemi Helsinki over last 60 years. Especially we look in to the probability of snow depth being more than 0 cm on a single day each year.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHJDulrttWxU",
        "colab_type": "text"
      },
      "source": [
        "The data is originally from FMI: https://ilmatieteenlaitos.fi/havaintojen-lataus#!/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "632LXgCdtem7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install packages not available by default in Colab\n",
        "!pip install arviz \n",
        "import arviz\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "UUms6UlztWxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import pystan\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.special as ss\n",
        "from scipy.stats import norm\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_cfzDCJai5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show warnings only once\n",
        "import warnings\n",
        "warnings.filterwarnings(action='once')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0xwiJJwtWxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load and cleanup data\n",
        "# ovewrite original column names\n",
        "# parse dates from several columns\n",
        "# clean up negative snow depths\n",
        "# About snow measurement in finnish: \n",
        "# Tilastoitava lumensyvyys mitataan aamulla klo 8 paikallista aikaa (kesäaikaan klo 9). Arvo -1 = ei lunta. Arvo 0 = havaintoasemalla ei ole lunta, mutta sen ympäristössä aukealla on.\n",
        "df = (pd.read_csv(\"https://raw.githubusercontent.com/dins/snow-depth/master/kaisaniemi.csv\", \n",
        "                 names=['year', 'month', 'day', 'clock', 'tzone', 'snow', 'temp'],\n",
        "                 header=0)\n",
        "                .assign(date = lambda d: pd.to_datetime(d[['year', 'month', 'day']]),\n",
        "                        snow = lambda d: d['snow'].clip(0),\n",
        "                        is_snow = lambda d: d['snow'] > 0)\n",
        "                  [['date', 'snow', 'is_snow', 'temp']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9b7r9PTtWxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHVfmKwrtWxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look into a specific day of the year\n",
        "# Remove years without snow depth measurement\n",
        "christmas = df.loc[lambda d: ~d['snow'].isnull() & (d['date'].dt.day == 24) & (d['date'].dt.month == 12)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjSX2whVtWxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "christmas.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-TcPNWbtWxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.scatterplot(x=\"date\", y=\"snow\", hue=\"is_snow\", data=christmas); # use ; in the end of line to hide values returned from scatterplot function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PN1wIs-Zmre",
        "colab_type": "text"
      },
      "source": [
        "Instead of snow depth in centimeters we will be looking at boolean variable is_snow. \n",
        "\n",
        "There are two reasons for this:\n",
        "*  We are are mostly interested in question if there is snow or not.\n",
        "*  Snow depth cannot not be negative and we would need to use a [zero inflated](https://en.wikipedia.org/wiki/Zero-inflated_model) model which is more complex.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ynqr61wY_M9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.scatterplot(x=\"date\", y=\"is_snow\", hue=\"is_snow\", data=christmas);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itbxEou_tWxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decade is sort of normalized time around year 2000\n",
        "# There is no boolean type in Stan so convert is_snow to int\n",
        "stan_data = christmas.assign(decade=lambda d: (d['date'].dt.year - 2000) / 10,\n",
        "                             is_snow=lambda d: d['is_snow'].astype(int))[['decade', 'is_snow']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpDTlORsH-y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wap5uSk2SiG",
        "colab_type": "text"
      },
      "source": [
        "# First simple model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZRHPYriIkbE",
        "colab_type": "text"
      },
      "source": [
        "Logit is a function that maps probability values from [0,1] to (-infinity, infinity): https://en.wikipedia.org/wiki/Logit\n",
        "\n",
        "We use it here to transform probability values to real values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oJUA_EDtWxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_model_code = '''\n",
        "data {\n",
        "   int N;\n",
        "   int<lower=0, upper=1> is_snow[N];\n",
        "}\n",
        "parameters {\n",
        "   real b;\n",
        "}\n",
        "model {\n",
        "  for (i in 1:N) {\n",
        "    is_snow[i] ~ bernoulli_logit(b);\n",
        "  }\n",
        "}\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syFNZiRDtWxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = pystan.StanModel(model_code=first_model_code)\n",
        "fit = model.sampling(data={'N': len(stan_data), **stan_data.to_dict(orient='list')}, iter=1000, chains=4)\n",
        "fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVJSse-GY6l8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arviz.plot_trace(fit);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5dxP7RPO8Fx",
        "colab_type": "text"
      },
      "source": [
        "The posterior distribution summarizes what you know after the data has been observed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOP4c1lhtWxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b_posterior = fit.extract('b')['b'] # Extract posterior draws for the parameter b. These sample values represent our posterior distribution.\n",
        "sns.distplot(b_posterior, fit=norm); # Looks like normally distributed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu3Z5ufEe8_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Similar plot with Arviz\n",
        "arviz.plot_posterior(fit, credible_interval=0.98);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL0WH8hpg4OC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "arviz.plot_density(fit);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLvnhsv2NdyH",
        "colab_type": "text"
      },
      "source": [
        "Let's undo the logit transformation i.e. convert b values from real scale to probability scale. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "kLpi18XjtWxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p_posterior = ss.expit(b_posterior) # inverse logit\n",
        "arviz.plot_posterior(p_posterior, credible_interval=0.98);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tULplD0XsyN",
        "colab_type": "text"
      },
      "source": [
        "# A bit more complex model - try to fit trend line over the years"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c5QFvdIYHUk",
        "colab_type": "text"
      },
      "source": [
        "Here we try to estimate the trend over time. We fit logistic regression to the is_snow variable.\n",
        "\n",
        "Also we do the inverse logit transform in Stan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PboY_HYtWxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "second_model_code = '''\n",
        "data {\n",
        "  int N;\n",
        "  int<lower=0, upper=1> is_snow[N];\n",
        "  real decade[N]; \n",
        "}\n",
        "parameters {\n",
        "  real b;\n",
        "  real k; \n",
        "}\n",
        "model {\n",
        "  for (i in 1:N) {\n",
        "    is_snow[i] ~ bernoulli_logit(k * decade[i] + b);\n",
        "  }\n",
        "}\n",
        "generated quantities {\n",
        "  real prob[N];\n",
        "  for (i in 1:N) {\n",
        "    prob[i] = inv_logit(k* decade[i] + b);\n",
        "  }\n",
        "}\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IERMpE2dtWxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = pystan.StanModel(model_code=second_model_code)\n",
        "fit2 = model2.sampling(data={'N': len(stan_data), **stan_data.to_dict(orient='list')}, iter=1000, chains=4)\n",
        "fit2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkVjYzPG5J5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with arviz.rc_context(rc={'plot.max_subplots': 10}): # Hangs if we try to plot all the 62 variables\n",
        "  arviz.plot_trace(fit2);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7shf7ausdaJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arviz.plot_trace(fit2, var_names=['b', 'k']);\n",
        "arviz.plot_posterior(fit2, var_names=['b', 'k']);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSU70NSWtWxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Has snow cover decreased significantly?\n",
        "params = fit2.extract(['prob[1]', 'prob[60]'])\n",
        "diff_samples = params['prob[1]'] - params['prob[60]']\n",
        "# probability of decrease\n",
        "np.mean(diff_samples > 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UNBhwX6tWxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now estimate snow probability for 2019\n",
        "decade_2019 = (2019 - 2000) / 10\n",
        "post_draws = fit2.extract(['b', 'k'])\n",
        "predictions = ss.expit(post_draws['b'] + post_draws['k'] * decade_2019)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt44p5HFtWx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.mean(predictions).round(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8F8FBvFtWx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(predictions);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1tBT-KjtWx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arviz.plot_posterior(predictions, credible_interval=0.9);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcdeJoehwUZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRwN3XKaT04o",
        "colab_type": "text"
      },
      "source": [
        "# Advanced state space model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCo6KgWPT6Ud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "statespace_code = '''\n",
        "data {\n",
        "   int N;\n",
        "   int<lower=0, upper=1> is_snow[N];\n",
        "}\n",
        "parameters {\n",
        "   vector[N] innovations;\n",
        "   real base;\n",
        "   real<lower=0> sigma;\n",
        "   real ytrend;\n",
        "}\n",
        "model {\n",
        "   innovations ~ normal(ytrend, 1);\n",
        "   is_snow ~ bernoulli_logit(base + sigma * cumulative_sum(innovations));\n",
        "   base ~ normal(0, 5);\n",
        "   sigma ~ normal(0, .1);\n",
        "   ytrend ~ normal(0, .1);\n",
        "}\n",
        "generated quantities {\n",
        "   vector[N] prob;\n",
        "   prob = inv_logit(base + sigma * cumulative_sum(innovations));\n",
        "}\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd9-uqOiUBEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ss = pystan.StanModel(model_code=statespace_code)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKWESG3bWV-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit_ss = model_ss.sampling(data={'N': len(stan_data), **stan_data.to_dict(orient='list')}, iter=1000, chains=4, control={\"adapt_delta\":0.95})\n",
        "fit_ss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIHB5t4CUgUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with arviz.rc_context(rc={'plot.max_subplots': 10}): # Hangs if we try to plot all variables\n",
        "  arviz.plot_trace(fit_ss);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9FBNV6fXbF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arviz.plot_trace(fit_ss, var_names=['base', 'sigma', 'ytrend']);\n",
        "arviz.plot_posterior(fit_ss, var_names=['base', 'sigma', 'ytrend']);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydaMe-69X45b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}